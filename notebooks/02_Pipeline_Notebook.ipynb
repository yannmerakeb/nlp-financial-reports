{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63b183ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys , types\n",
    "\n",
    "try:\n",
    "    import keras\n",
    "    keras.__version__ = '2.12.0'\n",
    "except ImportError:\n",
    "    pass\n",
    "# 2) Create a tf_keras alias so Transformers can import it\n",
    "if 'tf_keras' not in sys.modules:\n",
    "    try:\n",
    "        import keras as _k\n",
    "        m = types.ModuleType('tf_keras')\n",
    "        # Copy attributes from keras\n",
    "        for attr in dir(_k):\n",
    "            setattr(m, attr, getattr(_k, attr))\n",
    "        sys.modules['tf_keras'] = m\n",
    "    except ImportError:\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "# Setup project root and import path\n",
    "import os, sys\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "sys.path.insert(0, project_root)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d469fcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "653520fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Ticker: AAPL → CIK: 0000320193\n",
      "[+] Found 1 10-K filings\n",
      "[✓] Downloaded: AAPL_10K_2024.txt\n",
      "[+] Ticker: TSLA → CIK: 0001318605\n",
      "[+] Found 1 10-K filings\n",
      "[✓] Downloaded: TSLA_10K_2024.txt\n",
      "[+] Ticker: MSFT → CIK: 0000789019\n",
      "[+] Found 1 10-K filings\n",
      "[✓] Downloaded: MSFT_10K_2024.txt\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# Download raw data\n",
    "from src.data_loader import DataLoader\n",
    "\n",
    "# Define tickers and download directory\n",
    "tickers = [\"AAPL\", \"TSLA\", \"MSFT\"]\n",
    "loader = DataLoader(save_dir=\"data/raw\", delay=0.5)\n",
    "for t in tickers:\n",
    "    loader.fetch_10k_filings(t, count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ed78b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4161e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing AAPL_10K_2024.txt\n",
      "Preprocessed: data/processed\\AAPL_10K_2024.txt\n",
      "Preprocessing MSFT_10K_2024.txt\n",
      "Preprocessed: data/processed\\MSFT_10K_2024.txt\n",
      "Preprocessing TSLA_10K_2024.txt\n",
      "Preprocessed: data/processed\\TSLA_10K_2024.txt\n"
     ]
    }
   ],
   "source": [
    "# Preprocess raw filings\n",
    "from src.preprocessing import Preprocessor\n",
    "\n",
    "pp = Preprocessor(raw_dir=\"data/raw\", processed_dir=\"data/processed\")\n",
    "pp.batch_preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bda07116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset saved to: data/processed/reports.parquet\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Build main dataset\n",
    "from src.build_dataset import DatasetBuilder\n",
    "\n",
    "builder = DatasetBuilder(processed_dir=\"data/processed\", output_file=\"data/processed/reports.parquet\")\n",
    "builder.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd0ce634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[✓] Saved enriched data to data/processed/reports_with_market.parquet\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Enrich with market data (local CSV loader)\n",
    "from src.market_data import LocalMarketDataLoader\n",
    "import pandas as pd\n",
    "\n",
    "# Map tickers to your own CSV paths\n",
    "price_files = {\n",
    "        \"AAPL\": \"C:/Users/theod/OneDrive/Bureau/Theo/Master IEF Dauphine/S2/NLP/data/AAPL.csv\",\n",
    "        \"MSFT\": \"C:/Users/theod/OneDrive/Bureau/Theo/Master IEF Dauphine/S2/NLP/data/MSFT.csv\",\n",
    "        \"TSLA\": \"C:/Users/theod/OneDrive/Bureau/Theo/Master IEF Dauphine/S2/NLP/data/TSLA.csv\",\n",
    "    }\n",
    "reports = pd.read_parquet(\"data/processed/reports.parquet\")\n",
    "market_loader = LocalMarketDataLoader(price_files, output_file=\"data/processed/reports_with_market.parquet\")\n",
    "enriched = market_loader.enrich(reports)\n",
    "market_loader.save(enriched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5bcb5cac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved features to c:\\Users\\theod\\OneDrive\\Documents\\GitHub\\nlp-financial-reports\\data/processed/reports_features.parquet\n"
     ]
    }
   ],
   "source": [
    "#!pip install textstat\n",
    "#!pip install spacy\n",
    "\n",
    "# Compute linguistic features\n",
    "\n",
    "from src.features import FeatureEngineer\n",
    "fe = FeatureEngineer(input_file=os.path.join(project_root, \"data/processed/reports_with_market.parquet\"),\n",
    "                        output_file=os.path.join(project_root, \"data/processed/reports_features.parquet\"))\n",
    "fe.save()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4fddce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[✓] Saved TF-IDF features to data/processed/tfidf_features.parquet\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Generate TF-IDF features for SVM\n",
    "\n",
    "import pandas as pd\n",
    "from src.vectorization import TfidfFeatureExtractor\n",
    "\n",
    "df_feats = pd.read_parquet(os.path.join(project_root,\"data/processed/reports_features.parquet\"))\n",
    "texts = df_feats['item1a']  # focus on Risk Factors\n",
    "\n",
    "tfidf_extractor = TfidfFeatureExtractor(max_features=5000,\n",
    "                                         pca_components=0,\n",
    "                                         output_file=\"data/processed/tfidf_features.parquet\")\n",
    "tfidf_matrix = tfidf_extractor.fit_transform(texts)\n",
    "tfidf_extractor.save(tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10dd843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: keras 3.10.0\n",
      "Uninstalling keras-3.10.0:\n",
      "  Successfully uninstalled keras-3.10.0\n",
      "Collecting tf-keras\n",
      "  Downloading tf_keras-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting tensorflow<2.20,>=2.19 (from tf-keras)\n",
      "  Downloading tensorflow-2.19.0-cp312-cp312-win_amd64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\theod\\anaconda3\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (2.3.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\theod\\anaconda3\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\theod\\anaconda3\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\theod\\anaconda3\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\theod\\anaconda3\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\theod\\anaconda3\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\theod\\anaconda3\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\theod\\anaconda3\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\theod\\anaconda3\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\theod\\anaconda3\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\theod\\anaconda3\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\theod\\anaconda3\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\theod\\anaconda3\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\theod\\anaconda3\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\theod\\anaconda3\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\theod\\anaconda3\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (1.73.0)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in c:\\users\\theod\\anaconda3\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (2.19.0)\n",
      "Collecting keras>=3.5.0 (from tensorflow<2.20,>=2.19->tf-keras)\n",
      "  Using cached keras-3.10.0-py3-none-any.whl.metadata (6.0 kB)\n",
      "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in c:\\users\\theod\\anaconda3\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\theod\\anaconda3\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (3.14.0)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in c:\\users\\theod\\anaconda3\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (0.5.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\theod\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow<2.20,>=2.19->tf-keras) (0.44.0)\n",
      "Requirement already satisfied: rich in c:\\users\\theod\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\theod\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras) (0.1.0)\n",
      "Requirement already satisfied: optree in c:\\users\\theod\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras) (0.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\theod\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf-keras) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\theod\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf-keras) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\theod\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf-keras) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\theod\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf-keras) (2025.4.26)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\theod\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\theod\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\theod\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\theod\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\theod\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\theod\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\theod\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras) (0.1.0)\n",
      "Downloading tf_keras-2.19.0-py3-none-any.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.7/1.7 MB 18.8 MB/s eta 0:00:00\n",
      "Downloading tensorflow-2.19.0-cp312-cp312-win_amd64.whl (376.0 MB)\n",
      "   ---------------------------------------- 0.0/376.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.8/376.0 MB 10.1 MB/s eta 0:00:38\n",
      "    --------------------------------------- 4.7/376.0 MB 11.9 MB/s eta 0:00:32\n",
      "    --------------------------------------- 8.4/376.0 MB 14.1 MB/s eta 0:00:27\n",
      "   - -------------------------------------- 11.8/376.0 MB 15.1 MB/s eta 0:00:25\n",
      "   - -------------------------------------- 15.5/376.0 MB 15.2 MB/s eta 0:00:24\n",
      "   - -------------------------------------- 18.4/376.0 MB 15.2 MB/s eta 0:00:24\n",
      "   -- ------------------------------------- 21.8/376.0 MB 15.5 MB/s eta 0:00:23\n",
      "   -- ------------------------------------- 25.7/376.0 MB 15.8 MB/s eta 0:00:23\n",
      "   --- ------------------------------------ 28.8/376.0 MB 15.6 MB/s eta 0:00:23\n",
      "   --- ------------------------------------ 32.2/376.0 MB 15.9 MB/s eta 0:00:22\n",
      "   --- ------------------------------------ 36.4/376.0 MB 16.2 MB/s eta 0:00:21\n",
      "   ---- ----------------------------------- 41.4/376.0 MB 16.9 MB/s eta 0:00:20\n",
      "   ---- ----------------------------------- 45.9/376.0 MB 17.3 MB/s eta 0:00:20\n",
      "   ----- ---------------------------------- 51.9/376.0 MB 18.2 MB/s eta 0:00:18\n",
      "   ------ --------------------------------- 57.7/376.0 MB 18.8 MB/s eta 0:00:17\n",
      "   ------ --------------------------------- 64.5/376.0 MB 19.8 MB/s eta 0:00:16\n",
      "   ------- -------------------------------- 70.8/376.0 MB 20.4 MB/s eta 0:00:15\n",
      "   -------- ------------------------------- 75.5/376.0 MB 20.5 MB/s eta 0:00:15\n",
      "   -------- ------------------------------- 79.4/376.0 MB 20.5 MB/s eta 0:00:15\n",
      "   -------- ------------------------------- 84.4/376.0 MB 20.6 MB/s eta 0:00:15\n",
      "   --------- ------------------------------ 89.4/376.0 MB 20.9 MB/s eta 0:00:14\n",
      "   ---------- ----------------------------- 94.6/376.0 MB 21.0 MB/s eta 0:00:14\n",
      "   ---------- ----------------------------- 99.9/376.0 MB 21.2 MB/s eta 0:00:13\n",
      "   ---------- ---------------------------- 102.5/376.0 MB 20.9 MB/s eta 0:00:14\n",
      "   ----------- --------------------------- 106.2/376.0 MB 20.8 MB/s eta 0:00:13\n",
      "   ----------- --------------------------- 110.4/376.0 MB 20.7 MB/s eta 0:00:13\n",
      "   ----------- --------------------------- 114.3/376.0 MB 20.7 MB/s eta 0:00:13\n",
      "   ------------ -------------------------- 118.0/376.0 MB 20.6 MB/s eta 0:00:13\n",
      "   ------------ -------------------------- 122.2/376.0 MB 20.5 MB/s eta 0:00:13\n",
      "   ------------- ------------------------- 127.1/376.0 MB 20.7 MB/s eta 0:00:13\n",
      "   ------------- ------------------------- 133.7/376.0 MB 21.0 MB/s eta 0:00:12\n",
      "   -------------- ------------------------ 139.2/376.0 MB 21.2 MB/s eta 0:00:12\n",
      "   --------------- ----------------------- 145.2/376.0 MB 21.5 MB/s eta 0:00:11\n",
      "   --------------- ----------------------- 151.5/376.0 MB 21.8 MB/s eta 0:00:11\n",
      "   ---------------- ---------------------- 158.3/376.0 MB 22.1 MB/s eta 0:00:10\n",
      "   ----------------- --------------------- 164.4/376.0 MB 22.3 MB/s eta 0:00:10\n",
      "   ----------------- --------------------- 171.2/376.0 MB 22.6 MB/s eta 0:00:10\n",
      "   ------------------ -------------------- 176.7/376.0 MB 22.7 MB/s eta 0:00:09\n",
      "   ------------------ -------------------- 181.7/376.0 MB 22.7 MB/s eta 0:00:09\n",
      "   ------------------- ------------------- 186.9/376.0 MB 22.8 MB/s eta 0:00:09\n",
      "   ------------------- ------------------- 192.7/376.0 MB 23.0 MB/s eta 0:00:08\n",
      "   -------------------- ------------------ 197.9/376.0 MB 23.0 MB/s eta 0:00:08\n",
      "   --------------------- ----------------- 203.2/376.0 MB 23.1 MB/s eta 0:00:08\n",
      "   --------------------- ----------------- 208.1/376.0 MB 23.1 MB/s eta 0:00:08\n",
      "   ---------------------- ---------------- 214.2/376.0 MB 23.2 MB/s eta 0:00:07\n",
      "   ---------------------- ---------------- 218.9/376.0 MB 23.2 MB/s eta 0:00:07\n",
      "   ----------------------- --------------- 222.8/376.0 MB 23.1 MB/s eta 0:00:07\n",
      "   ----------------------- --------------- 226.2/376.0 MB 23.0 MB/s eta 0:00:07\n",
      "   ----------------------- --------------- 230.2/376.0 MB 22.9 MB/s eta 0:00:07\n",
      "   ------------------------ -------------- 234.4/376.0 MB 22.8 MB/s eta 0:00:07\n",
      "   ------------------------ -------------- 237.8/376.0 MB 22.8 MB/s eta 0:00:07\n",
      "   ------------------------ -------------- 240.6/376.0 MB 22.5 MB/s eta 0:00:07\n",
      "   ------------------------- ------------- 244.1/376.0 MB 22.4 MB/s eta 0:00:06\n",
      "   ------------------------- ------------- 247.2/376.0 MB 22.3 MB/s eta 0:00:06\n",
      "   ------------------------- ------------- 250.6/376.0 MB 22.1 MB/s eta 0:00:06\n",
      "   -------------------------- ------------ 253.8/376.0 MB 22.0 MB/s eta 0:00:06\n",
      "   -------------------------- ------------ 257.9/376.0 MB 22.0 MB/s eta 0:00:06\n",
      "   --------------------------- ----------- 261.4/376.0 MB 22.0 MB/s eta 0:00:06\n",
      "   --------------------------- ----------- 264.2/376.0 MB 22.0 MB/s eta 0:00:06\n",
      "   --------------------------- ----------- 269.2/376.0 MB 22.2 MB/s eta 0:00:05\n",
      "   ---------------------------- ---------- 274.2/376.0 MB 22.3 MB/s eta 0:00:05\n",
      "   ---------------------------- ---------- 279.4/376.0 MB 22.6 MB/s eta 0:00:05\n",
      "   ----------------------------- --------- 286.0/376.0 MB 22.9 MB/s eta 0:00:04\n",
      "   ------------------------------ -------- 292.0/376.0 MB 23.2 MB/s eta 0:00:04\n",
      "   ------------------------------ -------- 298.6/376.0 MB 23.6 MB/s eta 0:00:04\n",
      "   ------------------------------- ------- 304.6/376.0 MB 23.6 MB/s eta 0:00:04\n",
      "   -------------------------------- ------ 310.1/376.0 MB 23.7 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 316.7/376.0 MB 23.7 MB/s eta 0:00:03\n",
      "   --------------------------------- ----- 321.9/376.0 MB 23.6 MB/s eta 0:00:03\n",
      "   --------------------------------- ----- 326.4/376.0 MB 23.5 MB/s eta 0:00:03\n",
      "   ---------------------------------- ---- 332.4/376.0 MB 23.4 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 337.6/376.0 MB 23.6 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 342.6/376.0 MB 23.6 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 348.9/376.0 MB 23.7 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 354.7/376.0 MB 23.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 361.2/376.0 MB 23.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  367.3/376.0 MB 24.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  373.6/376.0 MB 24.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  375.9/376.0 MB 24.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  375.9/376.0 MB 24.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  375.9/376.0 MB 24.6 MB/s eta 0:00:01\n",
      "   --------------------------------------- 376.0/376.0 MB 23.4 MB/s eta 0:00:00\n",
      "Using cached keras-3.10.0-py3-none-any.whl (1.4 MB)\n",
      "Installing collected packages: keras, tensorflow, tf-keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 5] Accès refusé: 'c:\\\\Users\\\\theod\\\\anaconda3\\\\Lib\\\\site-packages\\\\tensorflow\\\\compiler\\\\mlir\\\\lite\\\\python\\\\_pywrap_converter_api.pyd'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "959b3a61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2e9fa070fac44288aa38de09ee6dbf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\theod\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\theod\\.cache\\huggingface\\hub\\models--sentence-transformers--all-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf49e404e88d4ef8ab89a125687f66a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3723d4d2eb740b8932e3961550cb4ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7664c83692484d2fb414c20859e8a3a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a47a259adbd47ff9ae4e04d107c5691",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61707c8a3f1543368faf35b93603ad34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f30f6ea282ff48d884299afb64d71302",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93758e766a3f4b0f809e5edbc9739e0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee1322c893724504a90c2e0d8c58879b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e86514be8a2548e59cde82aa30394e58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90dff4f9b9314ed9a3bfc7486cbff92b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de07570191b343bea0cbdc9b8130242a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[✓] Saved embedding features to data/processed/embedding_features.parquet\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Generate embedding features for neural models\n",
    "from src.vectorization import EmbeddingFeatureExtractor\n",
    "\n",
    "embed_extractor = EmbeddingFeatureExtractor(model_name='all-MiniLM-L6-v2',\n",
    "                                            output_file='data/processed/embedding_features.parquet')\n",
    "embeddings = embed_extractor.transform(texts)\n",
    "embed_extractor.save(embeddings)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
