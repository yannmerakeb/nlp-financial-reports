## ğŸ“ Project Overview

This project aims to detect ambiguous or strategically vague language in corporate financial disclosures (specifically SEC 10-K filings), using both linguistic feature engineering and transformer-based NLP models.  
We investigate whether such language correlates with poor post-disclosure market performance, suggesting potential obfuscation tactics by companies.

---

## ğŸ“ Project Structure

The project tree is organized as follows :

```bash
nlp-financial-reports/
â”‚
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ raw/ # Original 10-K filings and market data
â”‚ â””â”€â”€ processed/ # Cleaned and labeled text data
â”‚
â”œâ”€â”€ notebooks/
â”‚ â”œâ”€â”€ 01_data_exploration.ipynb
â”‚ â”œâ”€â”€ 02_feature_engineering.ipynb
â”‚ â””â”€â”€ 03_modeling.ipynb
â”‚
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ data_loader.py # EDGAR scraper and market data fetcher
â”‚ â”œâ”€â”€ preprocessing.py # Text cleaning and segmentation
â”‚ â”œâ”€â”€ features.py # Linguistic features, readability scores, etc.
â”‚ â”œâ”€â”€ baseline.py # TF-IDF + Logistic Regression (baseline model)
â”‚ â”œâ”€â”€ model.py # Fine-tuning transformer models (main model)
â”‚ â””â”€â”€ evaluation.py # Metrics, visualizations, comparison
â”‚
â”œâ”€â”€ results/
â”‚ â”œâ”€â”€ figures/ # Plots and graphs
â”‚ â””â”€â”€ metrics.json # Evaluation metrics
â”‚
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â””â”€â”€ .gitignore
```

---
## âš™ï¸ Setup & Installation (TO MODIFY/COMPLETE FROM THIS SECTION)

```bash
# Clone the repository
git clone https://github.com/your-username/nlp-financial-reports.git
cd nlp-financial-reports

# Create and activate a virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: .\venv\Scripts\activate

# Install required packages
pip install -r requirements.txt
```

---

## ğŸš€ How to Use

1. **Prepare the data**

   * Download and store raw 10-K filings in `data/raw/`
   * Use `src/data_loader.py` to extract text from SEC EDGAR and match filings to market data

2. **Preprocess and engineer features**

   * Run `notebooks/01_data_exploration.ipynb` and `02_feature_engineering.ipynb`
   * Extract linguistic features and readability scores

3. **Train models**

   * Use `src/baseline.py` to train the baseline TF-IDF + Logistic Regression model
   * Use `src/model.py` for fine-tuning transformer models (e.g., RoBERTa, FinBERT)

4. **Evaluate and compare**

   * Use `src/evaluation.py` to assess model performance
   * Compare results of the transformer model to the baseline
   * *(Optional)* Analyze correlation between detected ambiguity and market reaction

---

## ğŸ“Š Methodology

### Data Collection

Describe here how you gather and store 10-K filings and market data.

### Data Preparation

Explain your cleaning, segmentation, and labeling process.

### Feature Engineering

Detail linguistic features extracted (e.g., ambiguity indicators, readability scores, sentiment, etc.).

### Modeling

Explain the baseline model choice and architecture of the transformer model.

### Evaluation

Define metrics used (accuracy, F1-score, ROC AUC, etc.) and how you compare baseline and main models.

---

## ğŸ“ˆ Results

Summarize key findings, model performances, and any interesting observations regarding ambiguous language and market impact.

---

## ğŸ—£ï¸ Presentation

Include link or path to final slides and any supporting materials for your project presentation.

---